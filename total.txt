'''GameMasterOffline.py based on GameMaster.py

 Updated Jan. 30, 2025. Previously updated Nov. 17, 2024.
 See the test function at the end for how to customize
 the runs: choice of games and agents.

(C) University of Washington and S. Tanimoto, 2025.

Note that this Game Master is not enforcing the time limits
on moves.  The time limit will typically be important in
tournament play.

'''
import time
from time import sleep
USE_HTML = True
if USE_HTML: import gameToHTML

from winTesterForK import winTesterForK

from game_types import TTT, FIAR, Cassini

TIME_PER_MOVE = 1.0 # In seconds
INITIAL_STATE = TTT.initial_state

ALLOW_CERTAIN_IMPORTS = True

# Establish global variables, with defaults for now.
K = None
N = None
M = None
TURN_LIMIT = None

# To be called from WebGameAgent if using the web:
def set_game(game_type):
    global K, GAME_TYPE, TURN_LIMIT, N, M, INITIAL_STATE
    K = game_type.k
    N = game_type.n
    M = game_type.m
    GAME_TYPE = game_type
    TURN_LIMIT = game_type.turn_limit
    INITIAL_STATE = game_type.initial_state

PLAYERX = None
PLAYERO = None
def set_players(px, po):
    global PLAYERX, PLAYERO
    PLAYERX = px
    PLAYERO = po
    
FINISHED = False
def runGame():
    currentState = INITIAL_STATE
    player1 = PLAYERX
    player2 = PLAYERO
    renderCommentary('The Gamemaster says, "Players, introduce yourselves."')
    renderCommentary('     (Playing X:) '+player1.introduce())
    renderCommentary('     (Playing O:) '+player2.introduce())

    if USE_HTML:
        gameToHTML.startHTML(player1.nickname, player2.nickname, GAME_TYPE.short_name, 1)
    try:
        p1comment = player1.prepare(GAME_TYPE, 'X', player2.nickname)
    except Exception as e:
        print("Failed to prepare perhaps because: ", e)
        report = 'Player 1 ('+player1.nickname+' failed to prepare, and loses by default.'
        renderCommentary(report)
        if USE_HTML: gameToHTML.reportResult(report)
        report = 'Congratulations to Player 2 ('+player2.nickname+')!'
        renderCommentary(report)
        if USE_HTML: gameToHTML.reportResult(report)
        if USE_HTML: gameToHTML.endHTML()
        return
    try:
        p2comment = player2.prepare(GAME_TYPE, 'O', player1.nickname)
    except Exception as e:
        print("Failed to prepare perhaps because: ", e)
        report = 'Player 2 ('+player2.nickname+' failed to prepare, and loses by default.'
        renderCommentary(report)
        if USE_HTML: gameToHTML.reportResult(report)
        report = 'Congratulations to Player 1 ('+player1.nickname+')!'
        renderCommentary(report)
        if USE_HTML: gameToHTML.reportResult(report)
        if USE_HTML: gameToHTML.endHTML()
        return
        return
    
    renderCommentary('The Gamemaster says: We\'re playing '+GAME_TYPE.long_name+'.')
    renderCommentary('The Gamemaster says: Let\'s Play!')
    renderCommentary('The initial state is...')

    currentRemark = "The game is starting."
    if USE_HTML: gameToHTML.stateToHTML(currentState)
    XsTurn = True
    name = None
    global FINISHED
    FINISHED = False
    turnCount = 0
    printState(currentState)
    while not FINISHED:
        who = currentState.whose_move
        if XsTurn:
            playerResult = player1.make_move(currentState, currentRemark, TIME_PER_MOVE)
            name = player1.nickname
            XsTurn = False
        else:
            playerResult = player2.make_move(currentState, currentRemark, TIME_PER_MOVE)
            name = player2.nickname
            XsTurn = True
        moveAndState, currentRemark = playerResult
        if moveAndState==None:
            FINISHED = True; continue
        move, currentState = moveAndState
        moveReport = "Move is by "+who+" to "+str(move)
        renderCommentary(moveReport)
        utteranceReport = name +' says: '+currentRemark
        renderCommentary(utteranceReport)
        if USE_HTML: gameToHTML.reportResult(moveReport)
        if USE_HTML: gameToHTML.reportResult(utteranceReport)
        possibleWin = winTesterForK(currentState, move, K)
        if possibleWin != "No win":
            FINISHED = True
            currentState.finished = True
            printState(currentState)
            if USE_HTML: gameToHTML.stateToHTML(currentState, finished=True)
            renderCommentary(possibleWin)
            if USE_HTML: gameToHTML.reportResult(possibleWin)
            if USE_HTML: gameToHTML.endHTML()
            return
        printState(currentState)
        if USE_HTML: gameToHTML.stateToHTML(currentState)
        turnCount += 1
        if turnCount == TURN_LIMIT: FINISHED=True
        else:
            sleep(WAIT_TIME_AFTER_MOVES) # NOT TOO FAST.
    printState(currentState)
    if USE_HTML: gameToHTML.stateToHTML(currentState)
    who = currentState.whose_move
    renderCommentary("Game over; it's a draw.")
    if USE_HTML: gameToHTML.reportResult("Game Over; it's a draw")
    if USE_HTML: gameToHTML.endHTML()

def printState(s):
    global FINISHED
    board = s.board
    who = s.whose_move
    horizontalBorder = "+"+3*M*"-"+"+"
    renderCommentary(horizontalBorder)
    for row in board:
        line = "|"
        for item in row:
            line += " "+item+" "
        line += "|"
        renderCommentary(line)
    print(time.time())
    renderCommentary(horizontalBorder)
    if not FINISHED:
      renderCommentary("It is "+who+"'s turn to move.\n")

# Temporary function.  Remove when other channels are working.
def renderCommentary(stuff):
    print(stuff)
      
def render_move_and_state(move, state):
   # NOTE: THIS DEFN WILL BE OVERWRITTEN WHEN USED ON THE WEB.
   print(move, state)

def render_utterance(who, utterance):
   # NOTE: THIS DEFN WILL BE OVERWRITTEN WHEN USED ON THE WEB.
   print(who+' says: '+utterance)

# Not used in offline version:
#def async_runGame():
#    fut = ensure_future(runGame())

WAIT_TIME_AFTER_MOVES = 0.01
def set_wait_time(t):
    global WAIT_TIME_AFTER_MOVES
    WAIT_TIME_AFTER_MOVES = float(t)
     
def test():
    # Stand-alone test
    print("Starting stand-alone test of GameMaster.py")
    # Edit this to change what version of K-in-a-Row is used.
    set_game(Cassini) # default is Tic-Tac-Toe
    #set_game(FIAR) # Five in a Row
    # Import 1 or 2 agent files here.
    # If using only 1, create 2 instances of it, one of
    # which is a "twin".

    #import yourUWNetID_KInARow as h
    import natevitz_KInARow as h
    import RandomPlayer as j
    px = h.OurAgent()
    po = j.OurAgent()
    set_players(px, po)
    print("Players are set.")
    print("Now let's run the game.")
    runGame()

if __name__ == '__main__':
    test()
    
''' RandomPlayer.py
A player for the game of K-in-a-Row (on N by M board with forbidden squares.)

'''

from agent_base import KAgent
import game_types
from random import randint
GAME_TYPE = None

class OurAgent(KAgent):

    def __init__(self, twin=False):
        self.twin = twin
        self.nickname = 'Randy'
        if twin: self.nickname = "Randy-Junior"
        self.long_name = 'Random Walker'
        if twin: self.long_name = "Random Walker Junior"
        self.my_past_utterances = None
        self.opponent_past_utterances = None
        self.repeat_count = None
        self.utt_count = None
        
    # Receive and acknowledge information about the game from
    # the game master:
    def prepare(
            self,
            game_type,
            what_side_to_play,
            opponent_nickname,
            expected_time_per_move = 0.1, # Time limits can be
                                          # changed mid-game by the game master.
            utterances_matter = True):    # If False, just return 'OK' for each utterance.


       # Write code to save the relevant information in variables
       # local to this instance of the agent.
       # Game-type info can be in global variables.
       self.who_i_play = what_side_to_play
       self.opponent_nickname = opponent_nickname
       self.time_limit = expected_time_per_move
       global GAME_TYPE
       GAME_TYPE = game_type
       print("Oh, I love playing randomly at ", game_type.long_name)
       self.my_past_utterances = []
       self.opponent_past_utterances = []
       self.repeat_count = 0
       self.utt_count = 0
       if self.twin: self.utt_count = 5 # Offset the twin's utterances.

       return "OK"

    def introduce(self):
        if self.twin:
            remark = "Call me the Junior Random Walker."
        else:
            remark = "My name is "+self.long_name+". Or is it Walky Rander?"
        return remark

    def nickname(self): return self.nickname

    def make_move(self, state, last_utterance, time_limit):
        possibleMoves = successors_and_moves(state)
        myMove = chooseMove(possibleMoves)
        myUtterance = self.nextUtterance()
        newState, newMove = myMove
        return [[newMove, newState], myUtterance]

    def nextUtterance(self):
        if self.repeat_count > 1: return "I am randomed out now."
        n = len(UTTERANCE_BANK)
        if self.utt_count == n:
            self.utt_count = 0
            self.repeat_count += 1
        this_utterance = UTTERANCE_BANK[self.utt_count]
        self.utt_count += 1
        return this_utterance
   
# OPTIONAL THINGS TO KEEP TRACK OF:

#  WHO_MY_OPPONENT_PLAYS = other(WHO_I_PLAY)
#  MY_PAST_UTTERANCES = []
#  OPPONENT_PAST_UTTERANCES = []
#  UTTERANCE_COUNT = 0
#  REPEAT_COUNT = 0 or a table of these if you are reusing different utterances


# Figure out who the other player is.
# For example, other("X") = "O".
def other(p):
    if p=='X': return 'O'
    return 'X'

# Randomly choose a move.
def chooseMove(statesAndMoves):
    states, moves = statesAndMoves
    if states==[]: return None
    random_index = randint(0, len(states)-1)
    my_choice = [states[random_index], moves[random_index]]
    return my_choice

# The following is a Python "generator" function that creates an
# iterator to provide one move and new state at a time.
# It could be used in a smarter agent to only generate SOME of
# of the possible moves, especially if an alpha cutoff or beta
# cutoff determines that no more moves from this state are needed.
def move_gen(state):
    b = state.board
    p = state.whose_move
    o = other(p)
    mCols = len(b[0])
    nRows = len(b)

    for i in range(nRows):
        for j in range(mCols):
            if b[i][j] != ' ': continue
            news = do_move(state, i, j, o)
            yield [(i, j), news]

# This uses the generator to get all the successors.
def successors_and_moves(state):
    moves = []
    new_states = []
    for item in move_gen(state):
        moves.append(item[0])
        new_states.append(item[1])
    return [new_states, moves]

# Performa a move to get a new state.
def do_move(state, i, j, o):
            news = game_types.State(old=state)
            news.board[i][j] = state.whose_move
            news.whose_move = o
            return news
    
UTTERANCE_BANK = ["How's that for random?",
                  "Flip!",
                  "Spin!",
                  "I hope this is my lucky day!",
                  "How's this move for high noise to signal ratio?",
                  "Uniformly distributed. That's me.",
                  "Maybe I'll look into Bayes' Nets in the future.",
                  "Eenie Meenie Miney Mo.  I hope I'm getting K in a row.",
                  "Your choice is probably more informed than mine.",
                  "If I only had a brain.",
                  "I'd while away the hours, playing K in a Row.",
                  "So much fun.",
                  "Roll the dice!",
                  "Yes, I am on a roll -- of my virtual dice.",
                  "randint is my cousin.",
                  "I like to spread my influence around on the board."]


def test():
    global GAME_TYPE
    GAME_TYPE = game_types.TTT
    print(GAME_TYPE)
    h = OurAgent()
    print("I am ", h.nickname)
    
    ttt = GAME_TYPE.initial_state
    print("ttt initial state: ")
    print(ttt)
    print("successors_and_moves: ")
    print(successors_and_moves(ttt))

if __name__=="__main__":
    test()
'''
agent_base.py

Base class to be subclassed to create an agent for playing
"K-in-a-Row with Forbidden Squares" and related games.

Paul G. Allen School of Computer Science and Engineering,
University of Washington

THIS IS A TEMPLATE WITH STUBS FOR THE REQUIRED FUNCTIONS.

IMPORT IT INTO YOUR OWN AGENT MODULE AND SUBCLASS KAgent.
OVERRIDE METHODS AS NEEDED TO CREATE YOUR OWN AGENT.

YOU CAN PUT INTO YOUR MODULE WHATEVER ADDITIONAL FUNCTIONS 
YOU NEED IN ORDER TO ACHIEVE YOUR AGENT IMPLEMENTATION.

'''


AUTHORS = 'Jane Smith and Laura Lee' # Override this in your agent file.

import time

# Base class for all K-in-a-Row agents.

class KAgent:

    def __init__(self, twin=False):
        self.twin=False
        self.nickname = 'Nic'
        if twin: self.nickname += '2'
        self.long_name = 'Templatus Skeletus'
        if twin: self.long_name += ' II'
        self.persona = 'bland'
        self.voice_info = {'Chrome': 10, 'Firefox': 2, 'other': 0}
        self.playing = "don't know yet" # e.g., "X" or "O".
        self.image = None
        self.alpha_beta_cutoffs_this_turn = -1
        self.num_static_evals_this_turn = -1
        self.zobrist_table_num_entries_this_turn = -1
        self.zobrist_table_num_hits_this_turn = -1
        self.current_game_type = None

    def introduce(self):
        intro = '\nMy name is Templatus Skeletus.\n'+\
            '"An instructor" made me.\n'+\
            'Somebody please turn me into a real game-playing agent!\n' 
        return intro

    def nickname(self):
        return self.nickname
 
    # Receive and acknowledge information about the game from
    # the game master:
    def prepare(
            self,
            game_type,
            what_side_to_play,
            opponent_nickname,
            expected_time_per_move = 0.1, # Time limits can be
                                          # changed mid-game by the game master.
            utterances_matter=True):      # If False, just return 'OK' for each utterance,
                                          # or something simple and quick to compute
                                          # and do not import any LLM or special APIs.
                                          # During the tournament, this will be False..
       if utterances_matter:
           pass
           # Optionally, import your LLM API here.
           # Then you can use it to help create utterances.

       # Write code to save the relevant information in variables
       # local to this instance of the agent.
       # Game-type info can be in global variables.
       print("Change this to return 'OK' when ready to test the method.")
       return "Not-OK"
                
    def make_move(self, current_state, current_remark, time_limit=1000,
                  autograding=False, use_alpha_beta=True,
                  use_zobrist_hashing=False, max_ply=3,
                  special_static_eval_fn=None):
        print("make_move has been called")

        print("code to compute a good move should go here.")
        # Here's a placeholder:
        a_default_move = (0, 0) # This might be legal ONCE in a game,
        # if the square is not forbidden or already occupied.
    
        new_state = current_state # This is not allowed, and even if
        # it were allowed, the newState should be a deep COPY of the old.
    
        new_remark = "I need to think of something appropriate.\n" +\
        "Well, I guess I can say that this move is probably illegal."

        print("Returning from make_move")
        if not autograding:
            return [[a_default_move, new_state], new_remark]
        

        stats = [self.alpha_beta_cutoffs_this_turn,
                 self.num_static_evals_this_turn,
                 self.zobrist_table_num_entries_this_turn,
                 self.zobristt_table_num_hits_this_turn]
        

        return [[a_default_move, new_state]+stats, new_remark]

    # The main adversarial search function:
    def minimax(
            self,
            state,
            depth_remaining,
            pruning=False,
            alpha=None,
            beta=None):
        print("Calling minimax. We need to implement its body.")

        default_score = 0 # Value of the passed-in state. Needs to be computed.
    
        return [default_score, "my own optional stuff", "more of my stuff"]
        # Only the score is required here but other stuff can be returned
        # in the list, after the score, in case you want to pass info
        # back from recursive calls that might be used in your utterances,
        # etc. 
 
    def static_eval(self, state, game_type=None):
        print('calling static_eval. Its value needs to be computed!')
        # Values should be higher when the states are better for X,
        # lower when better for O.
        return 0
 

GAME_TYPE = None  # not known yet.
''' autograder.py
A simple tester for K-in-a-Row agents. Intended as a debugging aid.

We assume the program being tested here ALREADY CAN PLAY
ALL TYPES OF K-IN-A-ROW GAMES WITH THE Game_Master_Offline.py
program.

Therefore, the tests here will be additional tests for
specific aspects of the agent's capabilities.

Version of Feb. 5, 2025

 tests:

1. Static eval  (worth 10 points)
2. Minimax
  2a. Straight minimax (worth 10 points)
  2b. Alpha-beta (worth 10 points)

Passing these tests does NOT mean that the agent is
necessarily complying with all assignment requirements.

Also, eligibility for the class tournament may be
determined using additional factors, such as what libaries
might be imported, timing behavior, etc.

To use this, change "YourUWNetID_KInARow to your actual agent file's
name, make sure you have the imported files in the same folder.
(These include both the ones your agent imports and the ones imported
by this autograder.)
Then run the command:

python autograder.py
  or on some systems:
python3 autograder.py

'''

import game_types
import natevitz_KInARow as agent_module
import spec_static_by_table


def test_static_eval(agent):
    '''A static evaluation function should return high values
    on states that are good for X, and similarly strong but
    negative values on states that are good for O.
    Furthermore values should roughly track HOW good a
    state is for either player, and a state that's equally
    good for X and O should return a value of 0 or close to 0.

    The function should be robust to variations in the game
    type (i.e., initial state) and be able to work OK on
    whatever game states are presented to it, e.g., Tic-Tac-Toe,
    Cassini, etc. 

    Part 1: Tic-Tac-Toe
      State A:  win for O
      State B:  good for O
      State C:  neutral
      State D:  good for X
      State E:  win for X

    Part 2: Cassini
      State F:  win for O
      State G:  good for O
      State H:  neutral
      State I:  good for X
      State J:  win for X

'''

    Part_1_scores = [agent.static_eval(s, game_types.TTT) for s in [A, B, C, D, E]]
    num_inversions1 = count_inversions(Part_1_scores)

    #Part_2_scores = [0,0,0,0,0]
    Part_2_scores = [agent.static_eval(s, game_types.Cassini) for s in [F, G, H, I, J]]
    num_inversions2 = count_inversions(Part_2_scores)

    meta_score = (20 - (num_inversions1 + num_inversions2)) / 2
    #print("Your static_eval function gets ", meta_score, "out of 10.")
    return meta_score

def count_inversions(lst):
    n = len(lst)
    if n < 2: return 0

    # "Naive method" using nested loops; O(n^2) but code is simple
    # and we will have n = 5.  (Alternative uses modified Merge Sort and
    # needs 3 times as much code to achieve O(n log2 n) complexity.
    c = 0
    for i in range(n-1):
        for j in range(i+1, n):
            if lst[i] >= lst[j]: c += 1
    return c

A = game_types.State(initial_state_data = \
    [[['X',' ','O'],
      [' ','O','X'],
      ['O',' ','X']], "X"])

B = game_types.State(initial_state_data = \
    [[['X',' ','O'],
      ['X',' ',' '],
      ['O','X',' ']], "O"])

C = game_types.State(initial_state_data = \
    [[['X',' ','O'],
      [' ',' ',' '],
      [' ',' ',' ']], "X"])

D = game_types.State(initial_state_data = \
    [[['O','X','X'],
      [' ',' ','O'],
      ['X','O',' ']], "X"])

E = game_types.State(initial_state_data = \
    [[['X','O','O'],
      ['X',' ','X'],
      ['X',' ','O']], "O"])

F = game_types.State(initial_state_data = \
    [[[' ',' ',' ',' ',' ',' ',' ','X'],
      [' ','O','O','O','O','O',' ',' '],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ',' ','-','-','-','-','X','X'],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ','X','X',' ',' ',' ',' ',' '],
      [' ',' ',' ',' ',' ',' ','O',' ']], "X"])

G = game_types.State(initial_state_data = \
    [[[' ',' ',' ',' ',' ',' ',' ','X'],
      [' ','O','O',' ','O','O',' ',' '],
      [' ','O',' ','-','-',' ',' ',' '],
      [' ',' ','-','-','-','-','X','X'],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ','X','X',' ',' ',' ',' ',' '],
      [' ',' ',' ',' ',' ','O','O',' ']], "X"])

H = game_types.State(initial_state_data = \
    [[[' ',' ',' ',' ',' ',' ',' ',' '],
      [' ','O',' ',' ',' ',' ','O','X'],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ',' ','-','-','-','-',' ',' '],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ','X',' ',' ',' ',' ','X',' '],
      ['O',' ',' ',' ',' ',' ','O',' ']], "O"])

I = game_types.State(initial_state_data = \
    [[[' ',' ',' ','O',' ',' ',' ','X'],
      [' ','O',' ',' ',' ','O','O','X'],
      ['O',' ',' ','-','-','O',' ','X'],
      [' ',' ','-','-','-','-','X',' '],
      [' ',' ',' ','-','-','X',' ',' '],
      [' ','X','X',' ',' ',' ',' ',' '],
      [' ',' ','O',' ',' ',' ','O',' ']], "X"])

J = game_types.State(initial_state_data = \
    [[[' ','O',' ',' ',' ',' ',' ','O'],
      [' ','O',' ',' ',' ',' ',' ','O'],
      [' ','O',' ','-','-',' ',' ',' '],
      [' ',' ','-','-','-','-','X','O'],
      [' ',' ',' ','-','-',' ',' ',' '],
      [' ','X','X','X','X','X',' ',' '],
      [' ',' ',' ',' ',' ',' ','O',' ']], "O"])

MM_TEST_STATE = game_types.State(initial_state_data = \
    [[['O','O','X'],
      ['X',' ',' '],
      [' ',' ','X']], "O"])
                                
def test_minimax(agent, use_alpha_beta=False):
    '''Autograde the minimax capability of the agent as follows.
    Call the agent's prepare method, in case it needs to
    do any initialization prior to making moves.
    Call its make_move function with:
      autograding=True
      use_alpha_beta=Fase
      special_static_eval_fn = TTT_static_eval.
      This method will count the number of times it has been
      called and store it in NUM_CALLS_TO_STATIC_EVAL.
      It should also return best move and new state;
      hopefully the backed-up value of the new state, too.
'''
    spec_static_by_table.STATIC_EVAL_COUNT = 0
    GAME_TYPE = game_types.TTT
    prep_response = agent.prepare(GAME_TYPE, 'X', "Op Ponent")
    if prep_response != 'OK':
        print("Agent did not respond properly to the prepare command.")
        return
    print("Prepare was successful, it seems.")
    print("Next ... let's test minimaxing (and possibly alpha-beta pruning).")
    opponent_remark = "Do your thing."
    response = agent.make_move(\
                MM_TEST_STATE,
                opponent_remark,
                autograding=True,
                use_alpha_beta=use_alpha_beta,
                use_zobrist_hashing=False,
                max_ply=2,
                special_static_eval_fn=spec_static_by_table.special_static_eval_fn)

    print("Agent ", agent.nickname, " gives the following make_move response:")
    print(response)
    se_count = spec_static_by_table.STATIC_EVAL_COUNT
    print(se_count, "calls made to the special static evaluation function.")
    best_move = response[0][0]
    if best_move==(1,2):
        meta_minimax_score = 5
    else:
        print("minimax did NOT find the correct move")
        meta_minimax_score = 0
    if use_alpha_beta:
        if se_count == 8:
            meta_minimax_score += 5
        else:
            print(se_count, "is the wrong number of leaves evaluated during alpha-beta.")
            print("The correct number is 8.")
    
    if not use_alpha_beta and se_count == 12:
        meta_minimax_score += 5
    else:
        print("Without alpha-beta, your search should evaluate 12 leaf nodes.")
        print("Your search did", se_count)
    return meta_minimax_score        
    
if __name__ == "__main__":

    agent = agent_module.OurAgent()
    meta_se_score = test_static_eval(agent)
    print("The static_evaluation function's meta-score for ",
          agent.nickname, " is", meta_se_score)

    meta_minimax_score = test_minimax(agent)
    if meta_minimax_score==10:
        print("Your agent PASSES the minimax test!")
    meta_alpha_beta_score = test_minimax(agent, use_alpha_beta=True)
    if meta_alpha_beta_score==10:
        print("Your agent PASSES the alpha-beta test!")
    total_autograder_score = meta_se_score + meta_minimax_score + meta_alpha_beta_score    
    print("Your agent's total autograded score is ", total_autograder_score, "out of 30.0.") 
'''gameToHTML.py

'''
f = None
def startHTML(nickName1, nickName2, gameType, round=1):
    # Create a filename.
    fn = clean(nickName1)+'-vs-'+clean(nickName2)+'-in-'+clean(gameType)+'-round-'+str(round)+'.html'
    # To be added: Check for existing file by this name and create a new variation of it.
    global F
    try: F = open(fn, "w");
    except:
        print("Could not open the file "+fn+" for the game's HTML page.")
        return
    F.write('''
<html><head><title>K-in-a-Row game</title></head>
<body>
<h1>Game Report: ''')
    F.write(nickName1 + ' versus ' + nickName2 + ' in ' +gameType + ', round '+str(round))

    F.write(''' </h1>
''')

def reportResult(result):
    F.write("<h2>"+result+"</h2>\n")

def endHTML():
    F.write("</body></html>\n")
    F.close()

    
def clean(name):
    import re
    #print("in clean, name is", name)
    new_name = re.sub(' ', '-', name)
    new_name = re.sub('[^a-zA-Z10-9\\-]', '', new_name)
    return new_name

def stateToHTML(state, finished=False):
    board = state.board
    who = state.whose_move
    html = '''<table>
'''
    for row in board:
        html += "<tr>"
        for col in row:
            img = "gray32.png"
            if col=='X': img = "X32.png"
            elif col=='O': img = "O32.png"
            elif col=="-": img = "black32.png"
            html += "<td><img src=" + img + "></td>"
        html += "</tr>\n"
    html += "</table><br>\n"
    if not finished: html += "<h3>"+who+" to move.</h3>\n"
    F.write(html)
    
'''game_types.py

Defines a State class useful in all K-in-a-Row games.

Defines a KGame class as a base class for these games.

Also defines 3 specific versions of K-in-a-Row.
'''

#GAME_TYPE = None # Used in State.__str__

class State:
    def __init__(self, old=None, initial_state_data=None):
        if old==None:
            if initial_state_data==None:
                print("No old state or initial state data given to State().")
                raise Exception("in game_types.py, State() needs args.")
            else:
                # Translate string into initial state.
                self.board = initial_state_data[0]
                self.whose_move = initial_state_data[1]
        else:
            self.board = deep_copy(old.board)
            self.whose_move = old.whose_move # Changing whose move not done here.
        self.finished = False # Set to True if a win is detected.
        
    def __str__(self):
        text = ''
        M = len(self.board[0])
        horizontalBorder = "+"+3*M*"-"+"+\n"
        text += horizontalBorder
        for row in self.board:
            line = "|"
            for item in row:
                if item==' ': item = "."
                line += " "+item+" "
            line += "|\n"
            text += line
        text += horizontalBorder
        if not self.finished:
            text += "It is "+self.whose_move+"'s turn to move.\n"
        return text

            
    def change_turn(self):
        # Modify whose turn it is, in this state.
        if self.whose_move=="X": self.whose_move="O"
        else: self.whose_move="X"

def deep_copy(board_data):
    return [row[:] for row in board_data]

class Game_Type:
    def __init__(self, long_name, short_name, k, n, m, initial_state_data, turn_limit, default_time_per_move):
        self.long_name = long_name
        self.short_name = short_name
        self.k = k
        self.n = n
        self.m = m
        self.initial_state = State(initial_state_data = initial_state_data)
        self.turn_limit = turn_limit
        self.default_time_per_move = default_time_per_move

    def __str__(self):
        text = ''
        text += self.short_name + " is a Game_Type with k = "+str(self.k)
        return text
        
TTT_INITIAL_STATE_DATA = \
              [[[' ',' ',' '],
                [' ',' ',' '],
                [' ',' ',' ']], "X"]

TTT = Game_Type("Tic-Tac-Toe",
                 "TTT",
                 3,
                 3,
                 3,
                 TTT_INITIAL_STATE_DATA,
                 9,
                 1)

FIVE_INITIAL_STATE_DATA = \
              [[['-',' ',' ',' ',' ',' ','-'],
                [' ',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ',' '],
                ['-',' ',' ',' ',' ',' ','-']], "X"]

FIAR = Game_Type("Five-in-a-Row on a Seven-by-Seven Board with Corners Forbidden",
                 "5-in-a-Row",
                 5,
                 7,
                 7,
                 FIVE_INITIAL_STATE_DATA,
                 45,
                 0.25)

CASSINI_INITIAL_STATE_DATA = \
              [[[' ',' ',' ',' ',' ',' ',' ',' '],
                [' ','O',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ','-','-',' ',' ',' '],
                [' ',' ','-','-','-','-',' ',' '],
                [' ',' ',' ','-','-',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ',' ',' '],
                [' ',' ',' ',' ',' ',' ','O',' ']], "X"]

Cassini = Game_Type("Cassini (5 in a row that does not hit Saturn)",
                    "Cassini",
                    5,
                    7,
                    8,
                    CASSINI_INITIAL_STATE_DATA,
                    44,
                    1)

def test():
    global GAME_TYPE
    GAME_TYPE = Cassini
    print(GAME_TYPE.initial_state)

if __name__ == "__main__":
    test()
    
'''
natevitz_KInARow.py
Authors: Vitzthum, Nathan; Liu, Grace

An agent for playing "K-in-a-Row with Forbidden Squares" and related games.
CSE 415, University of Washington

THIS IS A TEMPLATE WITH STUBS FOR THE REQUIRED FUNCTIONS.
YOU CAN ADD WHATEVER ADDITIONAL FUNCTIONS YOU NEED IN ORDER
TO PROVIDE A GOOD STRUCTURE FOR YOUR IMPLEMENTATION.

'''

from agent_base import KAgent
from game_types import State, Game_Type

AUTHORS = 'Nathan Vitzthum and Grace Liu' 
 
import time # You'll probably need this to avoid losing a
 # game due to exceeding a time limit.

# Create your own type of agent by subclassing KAgent:

class OurAgent(KAgent):  # Keep the class name "OurAgent" so a game master
    # knows how to instantiate your agent class.

    def __init__(self, twin=False):
        self.twin=twin
        self.nickname = 'Nic'
        if twin: self.nickname += '2'
        self.long_name = 'Templatus Skeletus'
        if twin: self.long_name += ' II'
        self.persona = 'bland'
        self.voice_info = {'Chrome': 10, 'Firefox': 2, 'other': 0}
        self.playing = "don't know yet" # e.g., "X" or "O".
        self.alpha_beta_cutoffs_this_turn = 0
        self.num_static_evals_this_turn = 0
        self.zobrist_table_num_entries_this_turn = 0
        self.zobrist_table_num_hits_this_turn = 0
        self.current_game_type = None
        self.use_move_ordering = True # Enable move ordering by default
        self.move_ordering_benefit = 0  #Store cuttoffs for testing move ordering
        self.move_ordering_cutoff = 0

    def introduce(self):
        intro = '\nMy name is Templatus Skeletus.\n'+\
            '"An instructor" made me.\n'+\
            'Somebody please turn me into a real game-playing agent!\n'
        if self.twin: intro += "By the way, I'm the TWIN.\n"
        return intro

    # Receive and acknowledge information about the game from
    # the game master:
    def prepare(self, game_type, what_side_to_play, opponent_nickname, 
                expected_time_per_move = 0.1, utterances_matter=True):      
        # If False, just return 'OK' for each utterance,
        # or something simple and quick to compute
        # and do not import any LLM or special APIs.
        # During the tournament, this will be False..

        if utterances_matter:
           pass
           # Optionally, import your LLM API here.
           # Then you can use it to help create utterances.

        self.current_game_type = game_type
        self.playing = what_side_to_play
        self.opponent = opponent_nickname
        self.time_limit = expected_time_per_move
        return "OK"     
   
    # The core of your agent's ability should be implemented here:             
    def make_move(self, current_state, current_remark, time_limit=1000,
                  autograding=False, use_alpha_beta=True,
                  use_zobrist_hashing=False, max_ply=3,
                  special_static_eval_fn=None):
        print("make_move has been called")

        self.alpha_beta_cutoffs_this_turn = 0
        self.num_static_evals_this_turn = 0

        start_time = time.time()
        best_move, _ = self.minimax(current_state, max_ply, pruning=use_alpha_beta, 
                                    alpha=float('-inf'), beta=float('inf'), 
                                    start_time=start_time, time_limit=time_limit,
                                    special_static_eval_fn=None)
        new_state = self.perform_move(current_state, best_move)

        new_remark = "I think this is a good move."

        # need to use special evaluation function if autograding is true
        if autograding:
            stats = [self.alpha_beta_cutoffs_this_turn,
                     self.num_static_evals_this_turn,
                     self.zobrist_table_num_entries_this_turn,
                     self.zobrist_table_num_hits_this_turn]
            return [[best_move, new_state] + stats, new_remark]
        else:
            return [[best_move, new_state], new_remark]

    def minimax(self, state, depth_remaining, pruning=False,
                alpha=None, beta=None, start_time=None, time_limit=None,
                best_move_so_far=None, best_score_so_far=None, special_static_eval_fn=None):
        if time.time() - start_time > time_limit:
            # Time's up! Return the best move found so far, or a default if none found
            if best_move_so_far is not None:
                return best_move_so_far, best_score_so_far
            else:
                # Return a default move and a terrible score.  This is a fallback.
                possible_moves = self.get_legal_moves(state)
                if possible_moves:
                    return possible_moves[0], float('-inf')
                else:
                    return None, float('-inf')

        if depth_remaining == 0 or self.is_terminal(state):
            if special_static_eval_fn != None:
                score = special_static_eval_fn(state)
            else:
                self.num_static_evals_this_turn += 1
                score = self.static_eval(state, self.current_game_type)
            return None, score

        possible_moves = self.get_legal_moves(state)
        if not possible_moves:
            if special_static_eval_fn != None:
                score = special_static_eval_fn(state)
            else:
                self.num_static_evals_this_turn += 1
                score = self.static_eval(state, self.current_game_type)
            return None, score
        
        # Move Ordering (before the main loop)
        if self.use_move_ordering:
            possible_moves = self.order_moves(state, possible_moves)

        if state.whose_move == self.playing:  # Maximizing player
            best_move = None
            best_score = float('-inf')
            for move in possible_moves:
                new_state = self.perform_move(state, move)
                move_start_time = time.time() # check before starting each move
                if time.time() - start_time > time_limit:
                    # Time's up! Return the best move found so far, or a default if none found
                    if best_move_so_far is not None:
                        return best_move_so_far, best_score_so_far
                    else:
                        # Return a default move and a terrible score.  This is a fallback.
                        possible_moves = self.get_legal_moves(state)
                        if possible_moves:
                            return possible_moves[0], float('-inf')
                        else:
                            return None, float('-inf')

                _, score = self.minimax(new_state, depth_remaining - 1, pruning, alpha, beta, start_time, time_limit, best_move, best_score)

                if score > best_score:
                    best_score = score
                    best_move = move


                if pruning:
                    alpha = max(alpha, best_score)
                    if beta <= alpha:
                        self.alpha_beta_cutoffs_this_turn += 1
                        break  # Beta cutoff
            return best_move, best_score
        else:  # Minimizing player
            best_move = None
            best_score = float('inf')
            for move in possible_moves:
                new_state = self.perform_move(state, move)

                if time.time() - start_time > time_limit:
                    # Time's up! Return the best move found so far, or a default if none found
                    if best_move_so_far is not None:
                        return best_move_so_far, best_score_so_far
                    else:
                        # Return a default move and a terrible score.  This is a fallback.
                        possible_moves = self.get_legal_moves(state)
                        if possible_moves:
                            return possible_moves[0], float('-inf')
                        else:
                            return None, float('-inf')
                _, score = self.minimax(new_state, depth_remaining - 1, pruning, alpha, beta, start_time, time_limit, best_move, best_score)

                if score < best_score:
                    best_score = score
                    best_move = move

                if pruning:
                    beta = min(beta, best_score)
                    if beta <= alpha:
                        self.alpha_beta_cutoffs_this_turn += 1
                        break  # Alpha cutoff
            return best_move, best_score

    def static_eval(self, state, game_type):
        board = state.board
        size_n = game_type.n
        size_m = game_type.n
        my_symbol = self.playing
        opponent_symbol = 'O' if my_symbol == 'X' else 'X'
        score = 0
        k = game_type.k  # Win condition (number in a row)

        # Check rows, columns, and diagonals
        for i in range(size_n):
            for j in range(size_m):
                # Check horizontal
                if j <= size_m - k:
                    line = board[i][j:j+k]
                    score += self.evaluate_line(line, my_symbol, opponent_symbol, k)

                # Check vertical
                if i <= size_n - k:
                    line = [board[i+x][j] for x in range(k)]
                    score += self.evaluate_line(line, my_symbol, opponent_symbol, k)

                # Check diagonal (top-left to bottom-right)
                if i <= size_n - k and j <= size_m - k:
                    line = [board[i+x][j+x] for x in range(k)]
                    score += self.evaluate_line(line, my_symbol, opponent_symbol, k)

                # Check diagonal (top-right to bottom-left)
                if i <= size_n - k and j >= k - 1:
                    line = [board[i+x][j-x] for x in range(k)]
                    score += self.evaluate_line(line, my_symbol, opponent_symbol, k)
        return score

    def evaluate_line(self, line, my_symbol, opponent_symbol, k):
        score = 0
        line_str = ''.join(line)
        
        # Adjust scoring based on the number of symbols needed to win
        if line_str.count(my_symbol) == k - 1 and line_str.count(' ') == 1:
            score += 10  # Potential win
        elif line_str.count(my_symbol) == k - 2 and line_str.count(' ') == 2:
            score += 5   # Strong position
        elif line_str.count(opponent_symbol) == k - 1 and line_str.count(' ') == 1:
            score -= 9   # Opponent about to win
        elif line_str.count(opponent_symbol) == k - 2 and line_str.count(' ') == 2:
            score -= 4   # Opponent has a strong position
        
        # Add smaller scores for less critical positions
        score += line_str.count(my_symbol)
        score -= line_str.count(opponent_symbol)
        
        return score


    def get_legal_moves(self, state):
        moves = []
        board = state.board
        for i in range(len(board)):
            for j in range(len(board[i])):
                if board[i][j] == ' ':
                    moves.append((i, j))
        return moves

    def perform_move(self, state, move):
        new_state = State(old=state)
        new_state.board[move[0]][move[1]] = state.whose_move
        new_state.whose_move = 'O' if state.whose_move == 'X' else 'X'
        return new_state

    def is_terminal(self, state):
        board = state.board
        size = len(board)

        # Check rows and columns
        for i in range(size):
            if self.check_line(board[i]):  # Rows
                return True
            if self.check_line([board[j][i] for j in range(size)]):  # Columns
                return True

        # Check diagonals
        if self.check_line([board[i][i] for i in range(size)]):  # Top-left to bottom-right
            return True
        if self.check_line([board[i][size - 1 - i] for i in range(size)]):  # Top-right to bottom-left
            return True

        # Check for draw (no empty spaces)
        for row in board:
            if ' ' in row:
                return False  # Game is not a draw

        return True  # It's a draw

    def check_line(self, line):
        return (line[0] != ' ' and len(set(line)) == 1)
    
    def order_moves(self, state, moves):
        """Orders moves based on the static evaluation of the resulting states."""
        move_scores = []
        for move in moves:
            new_state = self.perform_move(state, move)
            score = self.static_eval(new_state, self.current_game_type)
            move_scores.append((move, score))

        # Sort moves in descending order of score if maximizing player, ascending if minimizing
        if state.whose_move == self.playing:
            move_scores.sort(key=lambda x: x[1], reverse=True)  # Maximizing
        else:
            move_scores.sort(key=lambda x: x[1])  # Minimizing

        ordered_moves = [move for move, score in move_scores]
        return ordered_moves
    
# OPTIONAL THINGS TO KEEP TRACK OF:

#  WHO_MY_OPPONENT_PLAYS = other(WHO_I_PLAY)
#  MY_PAST_UTTERANCES = []
#  OPPONENT_PAST_UTTERANCES = []
#  UTTERANCE_COUNT = 0
#  REPEAT_COUNT = 0 or a table of these if you are reusing different utterances


'''Special static evaluator for a specific set of
Tic-Tac-Toe states is provided here for testing
minimax and alpha-beta search.

'''

import game_types
SE_TABLE = {
'OOXXOX  X': 91,
'OOXXO X X': 10,
'OOXXO  XX': 20,
'OOXXXO  X': 11,
'OOXX OX X': 19,
'OOXX O XX': 11,
'OOXXX O X': 20,
'OOXX XO X': 109,
'OOXX  OXX': 11,
'OOXXX  OX': 30,
'OOXX X OX': 101,
'OOXX  XOX': 11 }

STATIC_EVAL_COUNT = 0
def special_static_eval_fn(state):
    global STATIC_EVAL_COUNT
    try: 
        code = state_quick_code(state)
    except:
        print("Warning: special static evaluation function is intended for TTT states only.")
        code = ''
    try:
        static_val = SE_TABLE[code]
    except KeyError:
        static_val = 0
        print("Warning: a state given to the special_static_eval_fn has no pre-computed static value in the table.")
    STATIC_EVAL_COUNT += 1
    return static_val

def state_quick_code(state):
    # Use as a hash, but there should never be collisions.
    b = state.board
    flat=sum(b, [])
    code="".join(flat)
    return code
'''winTesterForK.py
 This function takes a state s (with components s.board and s.whoseMove),
 a move of the form [i, j], and a parameter k.
 The move tells where the last move was made.  Any win is assumed
 to include the position of the last move.
 The parameter k tells how many Xs or Os in a row is required for a win.
 It returns either "No win" or a string describing where a win occurs.
'''

def winTesterForK(s, move, k):
    board = s.board
    who = s.whose_move
    moveI, moveJ = move
    whoWent = board[moveI][moveJ]
    if not whoWent in ['X', 'O']:
        return "Invalid Player Token in Move: '"+whoWent+"'"
    H = len(board) # height of board = num. of rows
    W = len(board[0]) # width of board = num. of cols.
    plusDirections  = [(0,1),(1,1),(1,0),(-1,1)] # E, NE, N, NW
    minusDirections = [(0,-1),(-1,-1),(-1,0),(1,-1)] # W, SW, S, SE
    for di in range(4):
        dp = plusDirections[di]
        dm = minusDirections[di]
        # count number of Xs (or Os) in plusDirection:
        count = 1
        i = moveI
        j = moveJ
        for step in range(k-1):
            i += dp[0]
            if i < 0 or i >= H: break # off the board 
            j += dp[1]
            if j < 0 or j >= W: break #   "   "    "
            if board[i][j] != whoWent: break # the run ends.
            count += 1
        # add in the number of Xs (or Os) in minusDirection:
        i = moveI
        j = moveJ
        for step in range(k-1):
            i += dm[0]
            if i < 0 or i >= H: break # off the board 
            j += dm[1]
            if j < 0 or j >= W: break #   "   "    "
            if board[i][j] != whoWent: break # the run ends.
            count += 1
            if count==k: break
        if count>=k:
            iWin = i - dm[0]
            jWin = j - dm[1]
            return "Win for "+whoWent+" at ["+str(iWin)+"]["+str(jWin)+"] in direction "+str(dp)
            
    return 'No win'

